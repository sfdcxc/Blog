# 爬虫之路
@author: Darcy
2019/3/2 19:03:03 

## 爬虫步骤
1. 抓取页面
2. 分析页面
3. 存储数据

## 依赖库
1. Requests 模拟网页请求
2. Selenum	爬虫测试
3. Aiohttp	异步Web服务的库
4. LXML	解析库
5. BeautifulSoup 解析库
6. PyQuery	解析库
7. Tesserorc OCR识别库
8. PyMySQL	存储库
9. PyMongo	存储库
10. redisPy	存储库
11. Flask	轻量级Web服务程序
12. tornado 支持异步的Web框架
## 数据库
1. Mysql
2. MongoDB
3. Redis
### 抓取页面
- 模拟浏览器向服务器发出请求
- 